P8451 Machine Learning in Public Health - Assignment 1
================
2023-2-14

In preparation for the analyses below, we will load the following
libraries:

``` r
library(caret)
```

    ## Loading required package: ggplot2

    ## Loading required package: lattice

``` r
library(tidyverse)
```

    ## ── Attaching packages
    ## ───────────────────────────────────────
    ## tidyverse 1.3.2 ──

    ## ✔ tibble  3.1.8      ✔ dplyr   1.0.10
    ## ✔ tidyr   1.2.1      ✔ stringr 1.5.0 
    ## ✔ readr   2.1.3      ✔ forcats 0.5.2 
    ## ✔ purrr   0.3.5      
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ✖ purrr::lift()   masks caret::lift()

``` r
library(dplyr)
```

# Part 0: Data Preprocessing

## Data Import and Cleaning

We will begin by importing the general health and physical activity data
collected by the **New York City Department of Health** using the
`read_csv` function. Next, we will clean the data by first applying the
`clean_names` function, then applying the `mutate` function to generate
variables with more representative variable names. All variables are
initially imported as numeric variables. According to the data codebook
provided, the following variables are factor variables with anywhere
between 2 to 6 levels:

- `hypertension` (chronic1)
- `diabetes` (chronic3)
- `asthma` (chornic4)
- `smoking` (tobacco1)
- `alcohol` (alcohol1)
- `physical_activity_minutes` (gpaq8totmin)
- `diet_cat` (habits5)
- `age_cat` (agegroup)
- `sex` (dem3)
- `hispanic` (dem4)
- `born_in_US` (dem8)
- `poverty_group` (povertygroup)

Finally, using the `select` function, we select only the newly labeled
variables, remove entries with NA using `na.omit`, and remove any
duplicate ID entries using the `distinct` function.

``` r
nyc_health = read_csv("./class4_p1.csv") %>% 
  janitor::clean_names() %>% 
  mutate(id = x1, 
         hypertension = factor(chronic1, labels = c("Yes", "No")),
         diabetes = factor(chronic3, labels = c("Yes, No")), 
         asthma = factor(chronic4, labels = c("Yes", "No")), 
         smoking = factor(tobacco1, labels = c("Most or All Days", 
                                               "Some Days", 
                                               "Never")), 
         alcohol = factor(alcohol1, labels = c("Most or All Days", 
                                               "Some Days", 
                                               "Never")), 
         physical_activity_minutes = gpaq8totmin, 
         walk_days = gpaq11days, 
         physical_activity_cat = factor(habits5, labels = c("Very Active", 
                                                            "Somewhat Active", 
                                                            "Not Very Active", 
                                                            "Not Active At All")), 
         diet_cat = factor(habits7, labels = c("Excellent",
                                               "Very Good", 
                                               "Good", 
                                               "Fair", 
                                               "Poor")), 
         age_cat = factor(agegroup, labels = c("18-24 Yrs", 
                                               "25-44 Yrs", 
                                               "45-64 Yrs", 
                                               "65+")), 
         sex = factor(dem3, labels = c("Male", "Female")), 
         hispanic = factor(dem4, labels = c("Yes", "No")), 
         born_in_US = factor(dem8, labels = c("USA", "Outside USA")), 
         poverty_group = factor(povertygroup, labels = c("<100%", 
                                                         "100-199%", 
                                                         "200-399%", 
                                                         "400-599%", 
                                                         "600% +", 
                                                         "Don't Know")), 
         healthy_days = healthydays) %>% 
  select(id, hypertension, diabetes, asthma, bmi, smoking, alcohol, 
         physical_activity_minutes, walk_days, physical_activity_cat, diet_cat, 
         age_cat, sex, hispanic, born_in_US, poverty_group, healthy_days) %>% 
  na.omit() %>% 
  distinct(id, .keep_all = TRUE)
```

    ## New names:
    ## Rows: 3811 Columns: 17
    ## ── Column specification
    ## ──────────────────────────────────────────────────────── Delimiter: "," dbl
    ## (17): ...1, chronic1, chronic3, chronic4, bmi, tobacco1, alcohol1, gpaq8...
    ## ℹ Use `spec()` to retrieve the full column specification for this data. ℹ
    ## Specify the column types or set `show_col_types = FALSE` to quiet this message.
    ## • `` -> `...1`

## Feature Selection: Identifying and Removing Correlated Predictors

Many machine learning algorithms are unable to differentiate between
highly correlated features. As such, we want to identify highly
correlated features that present the same mathematical information and
subsequently remove them, to avoid introducing error in our approach.

To complete this feature selection process, we will first select only
the numeric variables in our `nyc_health` data set, since correlations
can only be assessed with numeric variables. We will then apply the
`cor` function that will calculate correlations. These calculated
correlations will then be fed into the `findCorrelation` function with a
cutoff of **0.4**. The features that correlated at 0.4 and above will be
stored in a new objected labeled as `high_correlations`.

``` r
nyc_health_numeric = nyc_health %>% 
  select(where(is.numeric)) 

correlations = cor(nyc_health_numeric, use = "complete.obs")

high_correlations = findCorrelation(correlations, cutoff = 0.4)
```

Since there are no values in the `high_correlations` object, we can
conclude that there are no highly correlated variables in these data.

## Partitioning Data

For the purposes of this analysis, we will partition the data into
training and testing using a 70/30 split. This process involves applying
the `createDataPartition` function to generate a set of training and
testing data with equal proportion of individual with the outcome of
interest, i.e., `healthy_days`. The new object `train_index` contains
all the indexes of the rows in the original data set contained in the
70% split. The rows indexed to be in the 70% is assigned to a new
training data set, and the remaining 30% is assigned to a new testing
data set.

``` r
train_index = createDataPartition(nyc_health$healthy_days, p = 0.7, list = FALSE)

nyc_health_train <- nyc_health[train_index,]
nyc_health_test <- nyc_health[-train_index,]
```

# Part I: Implementing a Simple Prediction Pipeline

## Question 1: Fitting Prediction Models

In the code chunk below, we construct two linear regression models to
predict the number of days in a month an individual reported having good
physical health (`healthy_days`).

In the first model, **`healthy_days_model_1`**, we include features
containing basic demographic information (i.e., sex, age category, race,
place of birth, and poverty group), as well as medical information such
as BMI and history of chronic diseases, specifically for hypertension,
diabetes, and asthma.

In the second model, **`healthy_days_model_2`**, we include the same
features containing basic demographic information, as well as
self-reported assessments of levels of physical activity and diet.

``` r
healthy_days_model_1 = 
  nyc_health %>% 
  lm(healthy_days ~ sex + age_cat + hispanic + born_in_US + poverty_group + bmi + hypertension + diabetes + asthma, data = .)

healthy_days_model_2 = 
  nyc_health %>% 
  lm(healthy_days ~ sex + age_cat + hispanic + born_in_US + poverty_group + bmi + physical_activity_cat + diet_cat, data = .)
```

Below we tabulate the beta estimates, 95% CIs and p-values associated
with each feature for the two prediction models generated above.

``` r
healthy_days_model_1 %>% 
  broom::tidy() %>% 
  mutate(lower_CI = estimate - 1.96*std.error, 
         upper_CI = estimate + 1.96*std.error) %>% 
  select(term, estimate, lower_CI, upper_CI, p.value) %>% 
  knitr::kable(
    col.names = c('Term', 'beta Estimate', 'Lower 95% CI', 'Upper 95% CI', "p-value"),
    digits = 3, 
    caption = "Prediction Model 1 for Healthy Days")
```

| Term                    | beta Estimate | Lower 95% CI | Upper 95% CI | p-value |
|:------------------------|--------------:|-------------:|-------------:|--------:|
| (Intercept)             |        19.923 |       17.238 |       22.608 |   0.000 |
| sexFemale               |         0.029 |       -0.604 |        0.662 |   0.929 |
| age_cat25-44 Yrs        |        -1.214 |       -2.509 |        0.080 |   0.066 |
| age_cat45-64 Yrs        |        -2.507 |       -3.810 |       -1.203 |   0.000 |
| age_cat65+              |        -3.340 |       -4.733 |       -1.947 |   0.000 |
| hispanicNo              |         1.262 |        0.463 |        2.061 |   0.002 |
| born_in_USOutside USA   |         0.543 |       -0.132 |        1.217 |   0.115 |
| poverty_group100-199%   |         0.819 |       -0.225 |        1.864 |   0.124 |
| poverty_group200-399%   |         2.502 |        1.445 |        3.558 |   0.000 |
| poverty_group400-599%   |         2.480 |        1.400 |        3.561 |   0.000 |
| poverty_group600% +     |         2.872 |        1.829 |        3.914 |   0.000 |
| poverty_groupDon’t Know |         0.908 |       -0.398 |        2.215 |   0.173 |
| bmi                     |        -0.019 |       -0.069 |        0.031 |   0.460 |
| hypertensionNo          |         2.108 |        1.327 |        2.890 |   0.000 |
| diabetesYes, No2        |         1.108 |        0.073 |        2.144 |   0.036 |
| asthmaNo                |         4.027 |        2.749 |        5.305 |   0.000 |

Prediction Model 1 for Healthy Days

``` r
healthy_days_model_2 %>% 
  broom::tidy() %>% 
  mutate(lower_CI = estimate - 1.96*std.error, 
         upper_CI = estimate + 1.96*std.error) %>% 
  select(term, estimate, lower_CI, upper_CI, p.value) %>% 
  knitr::kable(
    col.names = c('Term', 'beta Estimate', 'Lower 95% CI', 'Upper 95% CI', "p-value"),
    digits = 3, 
    caption = "Prediction Model 2 for Healthy Days")
```

| Term                                   | beta Estimate | Lower 95% CI | Upper 95% CI | p-value |
|:---------------------------------------|--------------:|-------------:|-------------:|--------:|
| (Intercept)                            |        29.117 |       26.998 |       31.236 |   0.000 |
| sexFemale                              |        -0.034 |       -0.662 |        0.594 |   0.915 |
| age_cat25-44 Yrs                       |        -1.516 |       -2.796 |       -0.236 |   0.020 |
| age_cat45-64 Yrs                       |        -3.591 |       -4.863 |       -2.320 |   0.000 |
| age_cat65+                             |        -4.765 |       -6.084 |       -3.447 |   0.000 |
| hispanicNo                             |         1.166 |        0.371 |        1.962 |   0.004 |
| born_in_USOutside USA                  |         0.259 |       -0.413 |        0.930 |   0.451 |
| poverty_group100-199%                  |         0.372 |       -0.668 |        1.412 |   0.484 |
| poverty_group200-399%                  |         2.033 |        0.980 |        3.086 |   0.000 |
| poverty_group400-599%                  |         1.933 |        0.851 |        3.016 |   0.000 |
| poverty_group600% +                    |         2.090 |        1.039 |        3.142 |   0.000 |
| poverty_groupDon’t Know                |         0.329 |       -0.970 |        1.628 |   0.620 |
| bmi                                    |        -0.002 |       -0.052 |        0.047 |   0.925 |
| physical_activity_catSomewhat Active   |        -0.083 |       -0.815 |        0.649 |   0.824 |
| physical_activity_catNot Very Active   |        -2.161 |       -3.124 |       -1.198 |   0.000 |
| physical_activity_catNot Active At All |        -4.390 |       -5.973 |       -2.806 |   0.000 |
| diet_catVery Good                      |        -0.393 |       -1.424 |        0.638 |   0.456 |
| diet_catGood                           |        -1.156 |       -2.175 |       -0.137 |   0.026 |
| diet_catFair                           |        -2.674 |       -3.852 |       -1.497 |   0.000 |
| diet_catPoor                           |        -5.147 |       -6.883 |       -3.411 |   0.000 |

Prediction Model 2 for Healthy Days

## Question 2: Applying Prediction Models Within Test Data

First, we will use the `trainControl` function to set our validation
method. For the purposes of this analysis, we will use the 10-fold
crooss validation method.

``` r
control.settings = 
  trainControl(method = "cv", number = 10)
```

We will now apply these control settings within the `train` function
itself, which will be used to implement our algorithms. Below we

## Question 3: Discussion of Useful Implementation of Final Model

# Part II: Conducting an Unsupervised Analysis
